{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/atg/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-15 14:44:41 INFO  WordSegmenter:24 - Loading Word Segmentation model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModel, logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "# read data ignore last col\n",
    "import py_vncorenlp\n",
    "import os\n",
    "def seed_everything(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "if 'pwd' not in locals():\n",
    "    from transformers import PhobertTokenizer, AutoModel\n",
    "    from transformers import DataCollatorForTokenClassification\n",
    "    pwd = Path(os.getcwd())\n",
    "    save_dir = pwd / 'models'\n",
    "    rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=str(save_dir))\n",
    "    os.chdir(pwd)\n",
    "    seed_everything(25)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 6\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>rate</th>\n",
       "      <th>wseg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>Shop phục vụ tốt.</td>\n",
       "      <td>POS</td>\n",
       "      <td>4</td>\n",
       "      <td>shop phục_vụ tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26367</th>\n",
       "      <td>Bé nhỏ cũng có thể dắt xe, nhấc xe lên để chơi.</td>\n",
       "      <td>NEU</td>\n",
       "      <td>3</td>\n",
       "      <td>bé_nhỏ cũng có_thể dắt xe nhấc xe lên để chơi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29602</th>\n",
       "      <td>Áo không giống hình sản phẩm lỗi lừa đảo.</td>\n",
       "      <td>NEG</td>\n",
       "      <td>1</td>\n",
       "      <td>áo không giống hình sản_phẩm lỗi lừa_đảo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19747</th>\n",
       "      <td>ba lô phù hợp vs giá tiên, như hình.</td>\n",
       "      <td>NEU</td>\n",
       "      <td>3</td>\n",
       "      <td>ba_lô phù_hợp vs giá tiên như hình</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>Rất ok mua hoài vẫn ok.</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>rất ok mua hoài vẫn ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>5 sao nha!</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>sao nha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19210</th>\n",
       "      <td>Đóng gói sản phẩm rất đẹp và chắc chắn.</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>đóng_gói sản_phẩm rất đẹp và chắc_chắn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>Ưng quá.</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>ưng quá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11598</th>\n",
       "      <td>Thời gian giao hàng rất nhanh.Hàng ok.</td>\n",
       "      <td>POS</td>\n",
       "      <td>4</td>\n",
       "      <td>thời_gian giao hàng rất nhanh hàng ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>K biết cái này tác dụng thơm ở đâu.</td>\n",
       "      <td>NEG</td>\n",
       "      <td>1</td>\n",
       "      <td>biết cái này tác_dụng thơm đâu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment label  rate  \\\n",
       "6452                                 Shop phục vụ tốt.   POS     4   \n",
       "26367  Bé nhỏ cũng có thể dắt xe, nhấc xe lên để chơi.   NEU     3   \n",
       "29602        Áo không giống hình sản phẩm lỗi lừa đảo.   NEG     1   \n",
       "19747             ba lô phù hợp vs giá tiên, như hình.   NEU     3   \n",
       "1432                           Rất ok mua hoài vẫn ok.   POS     5   \n",
       "445                                         5 sao nha!   POS     5   \n",
       "19210          Đóng gói sản phẩm rất đẹp và chắc chắn.   POS     5   \n",
       "12179                                         Ưng quá.   POS     5   \n",
       "11598           Thời gian giao hàng rất nhanh.Hàng ok.   POS     4   \n",
       "8113               K biết cái này tác dụng thơm ở đâu.   NEG     1   \n",
       "\n",
       "                                                wseg  \n",
       "6452                                shop phục_vụ tốt  \n",
       "26367  bé_nhỏ cũng có_thể dắt xe nhấc xe lên để chơi  \n",
       "29602       áo không giống hình sản_phẩm lỗi lừa_đảo  \n",
       "19747             ba_lô phù_hợp vs giá tiên như hình  \n",
       "1432                          rất ok mua hoài vẫn ok  \n",
       "445                                          sao nha  \n",
       "19210         đóng_gói sản_phẩm rất đẹp và chắc_chắn  \n",
       "12179                                        ưng quá  \n",
       "11598          thời_gian giao hàng rất nhanh hàng ok  \n",
       "8113                  biết cái này tác_dụng thơm đâu  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data - data.csv', usecols=range(0, 3))\n",
    "data['wseg'] = data['comment'].apply(lambda x : \" \".join(simple_preprocess( \" \".join(rdrsegmenter.word_segment(x)))))\n",
    "display(data.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [14:20<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from CustomDataset import SentimentDataset\n",
    "bert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = PhobertTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "batch_size = 128\n",
    "dataset = SentimentDataset(data, tokenizer, max_len=256)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "bert.to(device)\n",
    "all_feats = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_masks'].to(device)\n",
    "        output = bert(input_ids, attention_mask)\n",
    "        all_feats.append(output[-1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31460, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feats = torch.load('all_feats.pt')\n",
    "X = np.concatenate([_.cpu().numpy() for _ in all_feats], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25168, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "Y = data['label'].tolist()\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "Y = le.transform(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=25)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.260 total time= 3.4min\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.260 total time= 3.3min\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.260 total time= 3.3min\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.260 total time= 3.3min\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.260 total time= 3.3min\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.272 total time=10.9min\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.276 total time=11.0min\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.277 total time=11.1min\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.272 total time=11.1min\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.271 total time=11.1min\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.583 total time= 2.4min\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.597 total time= 2.4min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100,], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['sigmoid', 'rbf', 'linear', 'poly']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv = N_SPLITS, scoring = 'f1_macro')\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
